{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ir739wb/ilyarekun/bc_project/centralized-learning/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T13:43:34.822477Z",
     "start_time": "2025-03-05T13:43:28.759435Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "from data_preprocessing import data_preprocessing_tumor_stratified\n",
    "from model import BrainCNN, EarlyStopping\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T13:43:37.414735Z",
     "start_time": "2025-03-05T13:43:36.620509Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = data_preprocessing_tumor_stratified()\n",
    "print(\"data was successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_loader.dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_images_per_class(loader):\n",
    "    class_counts = defaultdict(int)\n",
    "\n",
    "    for _, labels in loader:\n",
    "        for label in labels:\n",
    "            class_counts[label.item()] += 1  \n",
    "\n",
    "    return class_counts\n",
    "\n",
    "train_class_counts = count_images_per_class(train_loader)\n",
    "valid_class_counts = count_images_per_class(valid_loader)\n",
    "test_class_counts = count_images_per_class(test_loader)\n",
    "\n",
    "print(\"Train loader class counts:\")\n",
    "for class_label, count in train_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} images\")\n",
    "\n",
    "print(\"\\nValidation loader class counts:\")\n",
    "for class_label, count in valid_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} images\")\n",
    "\n",
    "print(\"\\nTest loader class counts:\")\n",
    "for class_label, count in test_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = BrainCNN()\n",
    "\n",
    "train_loss_metr, val_loss_metr, train_acc_metr, val_acc_metr, early_stopping = model.train_model(train_loader, valid_loader, num_epochs=50, patience=6, delta=0.004, learning_rate=0.002,momentum = 0.85, weight_decay = 0.07, save_path=\"./braincnn_prototype.weights\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "epochs = range(1, len(train_loss_metr) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss_metr, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(epochs, val_loss_metr, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc_metr, label=\"Train Accuracy\", marker=\"o\")\n",
    "plt.plot(epochs, val_acc_metr, label=\"Validation Accuracy\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=\"./braincnn_prototype.weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Создай модель\n",
    "model = BrainCNN()  # Убедись, что создаёшь объект модели\n",
    "model.to(device)\n",
    "\n",
    "# Загрузите веса без изменения\n",
    "state_dict = torch.load(save_path, map_location=device)\n",
    "\n",
    "# Если модель была обучена с DataParallel, убери \"module.\"\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Теперь можно обернуть в DataParallel, если используешь несколько GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Final evaluation on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_targets = []\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        test_targets.extend(target.cpu().numpy())\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "test_accuracy =  correct / total\n",
    "\n",
    "precision = precision_score(test_targets, test_preds, average='weighted')\n",
    "recall = recall_score(test_targets, test_preds, average='weighted')\n",
    "f1 = f1_score(test_targets, test_preds, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print('Metrics of the model on the test images:')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "with open(\"training_metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"train_loss\": train_loss_metr,\n",
    "        \"val_loss\": val_loss_metr,\n",
    "        \"train_acc\": train_acc_metr,\n",
    "        \"val_acc\": val_acc_metr,\n",
    "        \"accuracy\": test_accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }, f)\n",
    "\n",
    "#torch.save(model.state_dict(), \"./braincnn_prototype.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T13:52:17.122571Z",
     "start_time": "2025-03-05T13:52:16.846883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "with open(\"training_metrics1.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "train_loss_metr = metrics[\"train_loss\"]\n",
    "val_loss_metr = metrics[\"val_loss\"]\n",
    "train_acc_metr = metrics[\"train_acc\"]\n",
    "val_acc_metr = metrics[\"val_acc\"]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_metr, label='Train Loss')\n",
    "plt.plot(val_loss_metr, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Curve')\n",
    "\n",
    "# Accuracy curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc_metr, label='Train Accuracy')\n",
    "plt.plot(val_acc_metr, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Curve')\n",
    "\n",
    "plt.savefig(\"training_plots.png\", dpi=300, bbox_inches=\"tight\")  # Сохранение в файл\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cm = confusion_matrix(test_targets, test_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=['Glioma', 'Meningioma', 'notumor', 'Putuitary'], \n",
    "            yticklabels=['Glioma', 'Meningioma', 'notumor', 'Putuitary'])\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
