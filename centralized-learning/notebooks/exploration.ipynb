{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports and Environment Setup\n",
    "\n",
    "# Display system information (hostname and kernel) - useful for verifying the environment\n",
    "!hostnamectl\n",
    "\n",
    "# Change working directory to the project source folder\n",
    "#%cd /home/ir739wb/ilyarekun/bc_project/centralized-learning/src/\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add '../src' to the Python path so modules in that directory can be imported\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom data preprocessing function\n",
    "from src.data_preprocessing import data_preprocessing_tumor_stratified\n",
    "\n",
    "# Import model definition and early stopping utility\n",
    "from src.model import BrainCNN, EarlyStopping\n",
    "\n",
    "# Utility for counting occurrences per class\n",
    "from collections import defaultdict\n",
    "\n",
    "# Standard libraries for numeric operations, randomness, and file handling\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Libraries for plotting and visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch building blocks: neural network modules and optimizers\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "# Scikit-learn metrics for evaluation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "## Reproducibility: Set Random Seeds\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)                        # Seed CPU RNG\n",
    "torch.cuda.manual_seed(seed)                   # Seed current GPU\n",
    "torch.cuda.manual_seed_all(seed)               # Seed all GPUs (if using multi-GPU)\n",
    "random.seed(seed)                              # Seed Python built-in RNG\n",
    "np.random.seed(seed)                           # Seed NumPy RNG\n",
    "\n",
    "# Ensure deterministic behavior in cuDNN (at the cost of performance)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "## Load and Inspect Data\n",
    "\n",
    "# Perform stratified preprocessing for tumor classification, returning PyTorch DataLoaders\n",
    "train_loader, valid_loader, test_loader = data_preprocessing_tumor_stratified()\n",
    "\n",
    "print(\"Data was successfully loaded\")\n",
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_loader.dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_loader.dataset)}\")\n",
    "\n",
    "\n",
    "def count_images_per_class(loader):\n",
    "    \"\"\"\n",
    "    Count how many images belong to each class in a DataLoader.\n",
    "    Returns a dictionary mapping class_label -> count.\n",
    "    \"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "\n",
    "    # Iterate through batches of (data, labels)\n",
    "    for _, labels in loader:\n",
    "        for label in labels:\n",
    "            class_counts[label.item()] += 1\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "# Compute class distributions for train/validation/test sets\n",
    "train_class_counts = count_images_per_class(train_loader)\n",
    "valid_class_counts = count_images_per_class(valid_loader)\n",
    "test_class_counts = count_images_per_class(test_loader)\n",
    "\n",
    "# Print counts per class for the training set\n",
    "print(\"Train loader class counts:\")\n",
    "for class_label, count in train_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} images\")\n",
    "\n",
    "# Print counts per class for the validation set\n",
    "print(\"\\nValidation loader class counts:\")\n",
    "for class_label, count in valid_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} images\")\n",
    "\n",
    "# Print counts per class for the test set\n",
    "print(\"\\nTest loader class counts:\")\n",
    "for class_label, count in test_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} images\")\n",
    "\n",
    "\n",
    "## Instantiate and Train Model\n",
    "\n",
    "# Create a fresh instance of the BrainCNN model\n",
    "model = BrainCNN()\n",
    "\n",
    "# Train the model.\n",
    "# - train_loader: iterator over training data\n",
    "# - valid_loader: iterator over validation data\n",
    "# - num_epochs: maximum number of epochs to train\n",
    "# - patience: number of epochs to wait for improvement before early stopping\n",
    "# - delta: minimum change in validation loss to qualify as improvement\n",
    "# - learning_rate, momentum, weight_decay: optimizer hyperparameters\n",
    "# - save_path: file path to save the best model weights\n",
    "train_loss_metr, val_loss_metr, train_acc_metr, val_acc_metr, early_stopping = \\\n",
    "    model.train_model(\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        num_epochs=50,\n",
    "        patience=6,\n",
    "        delta=0.004,\n",
    "        learning_rate=0.002,\n",
    "        momentum=0.85,\n",
    "        weight_decay=0.07,\n",
    "        save_path=\"./braincnn_prototype.weights\"\n",
    "    )\n",
    "\n",
    "\n",
    "## Plot Training and Validation Curves (Loss and Accuracy)\n",
    "\n",
    "# Define the x-axis as epoch numbers\n",
    "epochs = range(1, len(train_loss_metr) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss Curves\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss_metr, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(epochs, val_loss_metr, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy Curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc_metr, label=\"Train Accuracy\", marker=\"o\")\n",
    "plt.plot(epochs, val_acc_metr, label=\"Validation Accuracy\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Load the Best Model Weights for Final Evaluation\n",
    "\n",
    "save_path = \"./braincnn_prototype.weights\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate a fresh model and move it to the chosen device\n",
    "model = BrainCNN()\n",
    "model.to(device)\n",
    "\n",
    "# Load the saved state dict, mapping tensors to the target device\n",
    "state_dict = torch.load(save_path, map_location=device)\n",
    "\n",
    "# If the model was saved using nn.DataParallel (prefix \"module.\"), strip it\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# If multiple GPUs are available, wrap the model in DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "## Evaluate Model on Test Set\n",
    "\n",
    "# Set model to evaluation mode (disable dropout, batchnorm updates, etc.)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "test_targets = []\n",
    "test_preds = []\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        # Move data and labels to the selected device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Obtain raw outputs (logits) from the model\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Predicted class is the index with the max logit\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "        # Store targets and predicted labels for metric computation\n",
    "        test_targets.extend(target.cpu().numpy())\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Compute overall accuracy on the test set\n",
    "test_accuracy = correct / total\n",
    "\n",
    "# Compute weighted precision, recall, and F1-score\n",
    "precision = precision_score(test_targets, test_preds, average='weighted')\n",
    "recall = recall_score(test_targets, test_preds, average='weighted')\n",
    "f1 = f1_score(test_targets, test_preds, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Metrics of the model on the test images:')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "## Save Training and Evaluation Metrics to Disk\n",
    "\n",
    "# Save all relevant metric lists and final test metrics in a pickle file\n",
    "with open(\"training_metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"train_loss\": train_loss_metr,\n",
    "        \"val_loss\": val_loss_metr,\n",
    "        \"train_acc\": train_acc_metr,\n",
    "        \"val_acc\": val_acc_metr,\n",
    "        \"accuracy\": test_accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }, f)\n",
    "\n",
    "\n",
    "## Reload Metrics and Plot Curves Again (e.g., from a Notebook Path)\n",
    "\n",
    "# Load previously saved metrics (note: adjust path as needed)\n",
    "with open(\"/home/ir739wb/ilyarekun/bc_project/centralized-learning/notebooks/training_metrics.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "train_loss_metr = metrics[\"train_loss\"]\n",
    "val_loss_metr = metrics[\"val_loss\"]\n",
    "train_acc_metr = metrics[\"train_acc\"]\n",
    "val_acc_metr = metrics[\"val_acc\"]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss Curve (reloaded from pickle)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_metr, label='Train Loss')\n",
    "plt.plot(val_loss_metr, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Curve')\n",
    "\n",
    "# Plot Accuracy Curve (reloaded from pickle)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc_metr, label='Train Accuracy')\n",
    "plt.plot(val_acc_metr, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Curve')\n",
    "\n",
    "# Save the combined plot to a PNG file with high resolution\n",
    "plt.savefig(\"training_plots.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Compute and Display Confusion Matrix\n",
    "\n",
    "# Compute confusion matrix given true labels and model predictions\n",
    "cm = confusion_matrix(test_targets, test_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=['Glioma', 'Meningioma', 'notumor', 'Putuitary'],\n",
    "    yticklabels=['Glioma', 'Meningioma', 'notumor', 'Putuitary']\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Save confusion matrix figure to file\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
