{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;94m Static hostname:\u001b[0m DGX\n",
      "\u001b[0;94m       Icon name:\u001b[0m computer-server\n",
      "\u001b[0;94m         Chassis:\u001b[0m server ðŸ–³\n",
      "\u001b[0;94m      Machine ID:\u001b[0m dedf5691225742ff95b33f842b0781cc\n",
      "\u001b[0;94m         Boot ID:\u001b[0m cb04df0ff1774eeda112c63867eeefdd\n",
      "\u001b[0;94mOperating System:\u001b[0m \u001b]8;;https://www.ubuntu.com/\u0007Ubuntu 24.04.2 LTS\u001b]8;;\u0007              \n",
      "\u001b[0;94m          Kernel:\u001b[0m Linux 6.8.0-53-generic\n",
      "\u001b[0;94m    Architecture:\u001b[0m x86-64\n",
      "\u001b[0;94m Hardware Vendor:\u001b[0m NVIDIA\n",
      "\u001b[0;94m  Hardware Model:\u001b[0m DGXA100 920-23687-2530-002\n",
      "\u001b[0;94mFirmware Version:\u001b[0m 1.29\n",
      "\u001b[0;94m   Firmware Date:\u001b[0m Tue 2024-08-06\n",
      "\u001b[0;94m    Firmware Age:\u001b[0m 7month 3w 5d\n"
     ]
    }
   ],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_link=\"masoudnickparvar/brain-tumor-mri-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ir739wb/miniconda3/envs/myenv/lib/python3.12/site-packages/flwr_datasets/utils.py:109: UserWarning: The currently tested dataset are ['mnist', 'ylecun/mnist', 'cifar10', 'uoft-cs/cifar10', 'fashion_mnist', 'zalando-datasets/fashion_mnist', 'sasha/dog-food', 'zh-plus/tiny-imagenet', 'scikit-learn/adult-census-income', 'cifar100', 'uoft-cs/cifar100', 'svhn', 'ufldl-stanford/svhn', 'sentiment140', 'stanfordnlp/sentiment140', 'speech_commands', 'LIUM/tedlium', 'flwrlabs/femnist', 'flwrlabs/ucf101', 'flwrlabs/ambient-acoustic-context', 'jlh/uci-mushrooms', 'Mike0307/MNIST-M', 'flwrlabs/usps', 'scikit-learn/iris', 'flwrlabs/pacs', 'flwrlabs/cinic10', 'flwrlabs/caltech101', 'flwrlabs/office-home', 'flwrlabs/fed-isic2019']. Given: masoudnickparvar/brain-tumor-mri-dataset.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "NUM_PARTITIONS = 5\n",
    "\n",
    "partitioner = IidPartitioner(num_partitions=NUM_PARTITIONS)\n",
    "# Let's partition the \"train\" split of the MNIST dataset\n",
    "# The MNIST dataset will be downloaded if it hasn't been already\n",
    "fds = FederatedDataset(dataset=dataset_link, partitioners={\"train\": partitioner})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset 'masoudnickparvar/brain-tumor-mri-dataset' doesn't exist on the Hub or cannot be accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We could load a single partition like this\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m partition_0 \u001b[38;5;241m=\u001b[39m fds\u001b[38;5;241m.\u001b[39mload_partition(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m partition_0\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/flwr_datasets/federated_dataset.py:177\u001b[0m, in \u001b[0;36mFederatedDataset.load_partition\u001b[0;34m(self, partition_id, split)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the partition specified by the idx in the selected split.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03mThe dataset is downloaded only when the first call to `load_partition` or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    Single partition from the dataset split.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_prepared:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_dataset()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset is not loaded yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/flwr_datasets/federated_dataset.py:314\u001b[0m, in \u001b[0;36mFederatedDataset._prepare_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prepare the dataset (prior to partitioning) by download, shuffle, replit.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    Run only ONCE when triggered by load_* function. (In future more control whether\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    happen before the resplitting.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_dataset(\n\u001b[1;32m    315\u001b[0m         path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_name, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_dataset_kwargs\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset, datasets\u001b[38;5;241m.\u001b[39mDatasetDict):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbably one of the specified parameter in `load_dataset_kwargs` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchange the return type of the datasets.load_dataset function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure to use parameter such that the return type is DatasetDict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe return type is currently: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/datasets/load.py:2132\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2127\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2128\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2129\u001b[0m )\n\u001b[1;32m   2131\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2132\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2133\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   2134\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   2135\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m   2136\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   2137\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   2138\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m   2139\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m   2140\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[1;32m   2141\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   2142\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   2143\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   2144\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m   2145\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2146\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[1;32m   2147\u001b[0m )\n\u001b[1;32m   2149\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/datasets/load.py:1853\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1852\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1853\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1854\u001b[0m     path,\n\u001b[1;32m   1855\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1856\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m   1857\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[1;32m   1858\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m   1859\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1860\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1861\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m   1862\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39m_require_default_config_name,\n\u001b[1;32m   1863\u001b[0m     _require_custom_configs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(config_kwargs),\n\u001b[1;32m   1864\u001b[0m )\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/datasets/load.py:1717\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[0;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/datasets/load.py:1643\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[1;32m   1640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevision \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1641\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hub or cannot be accessed.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1645\u001b[0m     dataset_script_path \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mhf_hub_download(\n\u001b[1;32m   1646\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   1647\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1650\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[1;32m   1651\u001b[0m     )\n",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset 'masoudnickparvar/brain-tumor-mri-dataset' doesn't exist on the Hub or cannot be accessed."
     ]
    }
   ],
   "source": [
    "# We could load a single partition like this\n",
    "partition_0 = fds.load_partition(0)\n",
    "partition_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
